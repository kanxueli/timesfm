{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户可定义IOH模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import njit\n",
    "import numpy as np\n",
    "# @njit\n",
    "def Check_If_IOH(time_series, srate, IOH_value, duration):\n",
    "    \"\"\"\n",
    "    Check if there is a period of intraoperative hypotension (IOH) in the time series.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series (1D array-like): The blood pressure time series.\n",
    "    - srate: Sampling rate of the time series (samples per second).\n",
    "    - IOH_value: Threshold value for IOH (blood pressure below this is considered hypotensive).\n",
    "    - duration: duration in seconds that defines IOH (must stay below IOH_value for this period).\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if IOH is detected, otherwise False.\n",
    "    \"\"\"\n",
    "    # 确保 time_series 是 numpy array\n",
    "    if isinstance(time_series, list):\n",
    "        time_series = np.array(time_series)\n",
    "\n",
    "    # 将Duration转换为采样点数\n",
    "    duration_samples = int(duration * srate)\n",
    "    \n",
    "    # 如果时间序列长度小于duration_samples，不可能满足IOH条件，直接返回False\n",
    "    if len(time_series) < duration_samples:\n",
    "        return False\n",
    "    \n",
    "    # 创建一个布尔掩码数组，标记低于IOH阈值的点\n",
    "    below_threshold = time_series < IOH_value\n",
    "    \n",
    "    # 使用滑动窗口检查是否存在连续的duration_samples个值都低于IOH_value\n",
    "    for i in range(len(below_threshold) - duration_samples + 1):\n",
    "        # 检查当前滑动窗口内的所有值是否都为True（即都低于IOH_value）\n",
    "        if np.all(below_threshold[i:i + duration_samples]):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def sliding_window_average(time_series, slide_len):\n",
    "    if slide_len <= 0:\n",
    "        raise ValueError(\"slide_len must be greater than 0\")\n",
    "    \n",
    "    # 存储滑动窗口的平均值\n",
    "    window_averages = []\n",
    "    \n",
    "    # 遍历序列，按滑动窗口大小取值\n",
    "    for i in range(0, len(time_series), slide_len):\n",
    "        # 获取当前窗口的值\n",
    "        window = time_series[i:i + slide_len]\n",
    "        # 计算窗口的平均值并存储\n",
    "        window_avg = round(np.nanmean(window), 2)\n",
    "        window_averages.append(window_avg)\n",
    "    \n",
    "    return window_averages\n",
    "\n",
    "\n",
    "# 只适用s为单位的抽样,且 slide_len必须能被stime整除，以及Duration能被slide_len整除，不然求出来的序列有误差。\n",
    "def Check_If_IOH_Combined_S(time_series, stime, IOH_value, Duration, slide_len):\n",
    "    # Duration 和 滑动窗口长度转为采样点\n",
    "    duration_samples = int(Duration / slide_len)\n",
    "    slide_samples = slide_len\n",
    "    \n",
    "    # 计算滑动窗口的平均值\n",
    "    if slide_samples == 1:\n",
    "        smoothed_series = time_series\n",
    "    else:\n",
    "        # smoothed_series = Count_Windows_MovingAvg(time_series, slide_samples)\n",
    "        smoothed_series = sliding_window_average(time_series, slide_samples)\n",
    "\n",
    "    # Step 2: 对平滑后的序列进行低血压检测\n",
    "    if duration_samples == 1:\n",
    "        evt = np.nanmax(smoothed_series) < IOH_value\n",
    "    else:\n",
    "        # Step 3: 逐点判断\n",
    "        evt = Check_If_IOH(smoothed_series, 1, IOH_value, duration_samples)\n",
    "        # evt = np.nanmax(sliding_window_value) < IOH_value\n",
    "\n",
    "    # print(\"evt:\", evt, \"max:\", np.nanmax(sliding_window_count) )\n",
    "    return evt\n",
    "\n",
    "def round_data_to_two_decimals(data):\n",
    "    return np.where(np.isnan(data), data, np.round(data, 2))\n",
    "\n",
    "def user_definable_IOH(time_series):\n",
    "    predcition_lables = []\n",
    "    for i in time_series:\n",
    "        predcition_lables.append(Check_If_IOH_Combined_S(i, 1, 65, 30, 1))\n",
    "    return predcition_lables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VitalDB低血压数据数据切片和重组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "def get_batched_data_fn(\n",
    "    batch_size: int = 128, \n",
    "    # context_len: int = 120, \n",
    "    # horizon_len: int = 24,\n",
    "):\n",
    "    # 读取CSV文件\n",
    "    csv_file = '/home/likx/time_series_forecasting/IOH_Datasets_Preprocess/vitaldb/vitaldb_test_data.csv'\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # # 使用前向填充和后向填充处理NaN值\n",
    "    # data = data.ffill().bfill()\n",
    "\n",
    "    # 数据预处理前总数据\n",
    "    print(\"源数据长度：\", len(data))\n",
    "    # 统计处理后 examples 中 label 列的分布\n",
    "    label_counts = data['label'].value_counts(normalize=True) * 100\n",
    "    print(\"处理前的Label分布 (%):\")\n",
    "    print(label_counts)\n",
    "\n",
    "    # 移除 prediction_mbp 为 '[]' 的行\n",
    "    # data = data.loc[data['prediction_mbp'] != '[]']\n",
    "\n",
    "    # 定义处理序列数据的函数，直接通过空格拆分并转换为浮点数列表，且完成重采样\n",
    "    def parse_sequence(sequence_str, skip_rate=0, sample_type='avg_sample'):\n",
    "        try:\n",
    "            sequence_list = sequence_str.split()\n",
    "            sequence_array = np.array([np.nan if x == 'nan' else float(x) for x in sequence_list])\n",
    "            mean_value = round(np.nanmean(sequence_array), 2)\n",
    "            sequence_array_filled = np.where(np.isnan(sequence_array), mean_value, sequence_array)\n",
    "            if np.any(np.isnan(sequence_array_filled)):\n",
    "                return [] \n",
    "                    \n",
    "            if skip_rate > 0: # 如果需要重采样\n",
    "                if sample_type == 'skip_sample':\n",
    "                    sequence_array_filled = sequence_array_filled[::skip_rate]\n",
    "                elif sample_type == 'avg_sample': #默认按平均值进行采样\n",
    "                    sequence_array_filled = sliding_window_average(sequence_array_filled, skip_rate)\n",
    "\n",
    "            return sequence_array_filled\n",
    "        except ValueError:\n",
    "            return [] \n",
    "    # 初始化 defaultdict\n",
    "    examples = defaultdict(list)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        bts = parse_sequence(row['bts'][1:-1], skip_rate=0, sample_type='skip_sample') #采样周期是：2*skip_rate\n",
    "        hrs = parse_sequence(row['hrs'][1:-1], skip_rate=0, sample_type='skip_sample')\n",
    "        dbp = parse_sequence(row['dbp'][1:-1], skip_rate=0, sample_type='skip_sample')\n",
    "        mbp = parse_sequence(row['mbp'][1:-1], skip_rate=0, sample_type='skip_sample')\n",
    "        prediction_mbp = parse_sequence(row['prediction_mbp'][1:-1], skip_rate=0, sample_type='skip_sample')\n",
    "        # print(len(bts), len(hrs), len(dbp), len(mbp), len(prediction_mbp))\n",
    "        if len(bts) != 450 or len(hrs) != 450 or len(dbp) != 450 or\\\n",
    "            len(mbp) != 450 or len(prediction_mbp) != 150:\n",
    "            continue\n",
    "        \n",
    "        examples['caseid'].append(row['caseid'])\n",
    "        examples['stime'].append(row['stime'])\n",
    "        examples['ioh_stime'].append(row['ioh_stime'])\n",
    "        examples['ioh_dtime'].append(row['ioh_dtime'])\n",
    "        examples['age'].append(row['age']) # np.full(len(bts), row['age'])\n",
    "        examples['sex'].append(row['sex'])\n",
    "        examples['bmi'].append(row['bmi'])\n",
    "        examples['label'].append(Check_If_IOH_Combined_S(prediction_mbp, 1, 65, 30, 1))\n",
    "        examples['bts'].append(bts)\n",
    "        examples['hrs'].append(hrs)\n",
    "        examples['dbp'].append(dbp)\n",
    "        examples['inputs'].append(mbp)\n",
    "        examples['outputs'].append(prediction_mbp)\n",
    "\n",
    "    # 修正统计处理后的样本数量\n",
    "    print(\"处理后的测试样本数量:\", len(examples['caseid']))\n",
    "\n",
    "    # 统计处理后 examples 中 label 列的分布\n",
    "    label_counts = pd.Series(examples['label']).value_counts(normalize=True) * 100\n",
    "    print(\"处理后的Label分布 (%):\")\n",
    "    print(label_counts)\n",
    "# examples\n",
    "\n",
    "    '''\n",
    "        (num_examples - 1) // batch_size：这是整除运算，用来计算可以完全容纳 batch_size 个样本的完整批次数量。\n",
    "        1 +：确保即使在最后的批次不足 batch_size 的时候，仍然会生成这个未满的批次。\n",
    "    '''\n",
    "    def data_fn(): # 批次生成器函数\n",
    "        for i in range(1 + (len(data) - 1) // batch_size):\n",
    "            yield {k: v[(i * batch_size) : ((i + 1) * batch_size)] for k, v in examples.items()}\n",
    "    \n",
    "    return data_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "# Define metrics\n",
    "def mse(y_pred, y_true):\n",
    "  y_pred = np.array(y_pred)\n",
    "  y_true = np.array(y_true)\n",
    "  return np.mean(np.square(y_pred - y_true), axis=1, keepdims=True)\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "  y_pred = np.array(y_pred)\n",
    "  y_true = np.array(y_true)\n",
    "  return np.mean(np.abs(y_pred - y_true), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimesFM模型加载与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源数据长度： 14513\n",
      "处理前的Label分布 (%):\n",
      "label\n",
      "False    87.900503\n",
      "True     12.099497\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2265376/1870346327.py:31: RuntimeWarning: Mean of empty slice\n",
      "  mean_value = round(np.nanmean(sequence_array), 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的测试样本数量: 13073\n",
      "处理后的Label分布 (%):\n",
      "False    92.342997\n",
      "True      7.657003\n",
      "Name: proportion, dtype: float64\n",
      "Loading Model Finish.\n",
      "Finished batch 101 linear in 0.34670519828796387 seconds\n",
      "eval_mae_timesfm: 5.582376960559375\n",
      "eval_mae_xreg_timesfm: 10.527234063120654\n",
      "eval_mae_xreg: 83.0502415494033\n",
      "eval_mse_timesfm: 86.06718922410472\n",
      "eval_mse_xreg_timesfm: 216.33579340607128\n",
      "eval_mse_xreg: 7089.462976952161\n",
      "eval_pred_lable_timesfm --Prediction Results:\n",
      "auroc=0.793, auprc=0.631 acc=0.941, F1=0.616, PPV=61.3, NPV=96.8, TN=11663, fp=392, fn=381, TP=620\n",
      "eval_pred_lable_xreg_timesfm --Prediction Results:\n",
      "auroc=0.615, auprc=0.305 acc=0.877, F1=0.276, PPV=25.2, NPV=94.1, TN=11146, fp=909, fn=695, TP=306\n",
      "eval_pred_lable_xreg --Prediction Results:\n",
      "auroc=0.500, auprc=0.538 acc=0.077, F1=0.142, PPV=7.7, NPV=nan, TN=0, fp=12055, fn=0, TP=1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2265376/4095084012.py:111: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  testres = 'auroc={:.3f}, auprc={:.3f} acc={:.3f}, F1={:.3f}, PPV={:.1f}, NPV={:.1f}, TN={}, fp={}, fn={}, TP={}'.format(auroc, auprc, acc, f1, tp/(tp+fp)*100, tn/(tn+fn)*100, tn, fp, fn, tp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import timesfm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "context_len = 450\n",
    "horizon_len = 150\n",
    "\n",
    "# 数据集加载与批量化\n",
    "bs = 128\n",
    "input_data = get_batched_data_fn(batch_size=bs)\n",
    "\n",
    "# Loading TimesFM in pytorch version\n",
    "tfm = timesfm.TimesFm(\n",
    "      hparams=timesfm.TimesFmHparams(\n",
    "          backend=\"gpu\",\n",
    "          per_core_batch_size=32,      \n",
    "          horizon_len=horizon_len,\n",
    "      ),\n",
    "      checkpoint=timesfm.TimesFmCheckpoint(\n",
    "         version=\"torch\",\n",
    "          # huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"\n",
    "          path=\"/home/data/times-forecasting/checkpoints/timesfm-1.0-200m-pytorch/torch_model.ckpt\"),\n",
    "  )\n",
    "print(\"Loading Model Finish.\")\n",
    "\n",
    "# Loading TimesFM in JAX/PAX version\n",
    "# tfm = timesfm.TimesFm(\n",
    "#       hparams=timesfm.TimesFmHparams(\n",
    "#           backend=\"gpu\",\n",
    "#           per_core_batch_size=32,      \n",
    "#           horizon_len=horizon_len,\n",
    "#       ),\n",
    "#       checkpoint=timesfm.TimesFmCheckpoint(\n",
    "#          version=\"jax\",\n",
    "#          step=1100000,\n",
    "#          path=\"/home/likx/time_series_forecasting/datasets_and_checkpoints/timesfm-1.0-200m/checkpoints/\"),\n",
    "#   )\n",
    "# print(\"Loading Model Finish.\")\n",
    "\n",
    "\n",
    "# Benchmark\n",
    "metrics = defaultdict(list)\n",
    "ground_true_labels = []\n",
    "for i, example in enumerate(input_data()):\n",
    "    if np.array(example[\"inputs\"]).shape != (bs, context_len):\n",
    "        continue\n",
    "\n",
    "    raw_forecast, _ = tfm.forecast(\n",
    "        inputs=example[\"inputs\"], freq=[0] * len(example[\"inputs\"])\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    # Forecast with covariates\n",
    "    # Output: new forecast, forecast by the xreg\n",
    "    cov_forecast, ols_forecast = tfm.forecast_with_covariates(  \n",
    "        inputs=example[\"inputs\"],\n",
    "        dynamic_numerical_covariates={\n",
    "            #   \"body_temperature\": example[\"bts\"],\n",
    "            #   \"heart_rate\": example[\"hrs\"],\n",
    "            #   \"diastolic_blood_pressure\": example[\"dbp\"],\n",
    "        },\n",
    "        dynamic_categorical_covariates={},\n",
    "        static_numerical_covariates={\n",
    "            \"age\": example[\"age\"],\n",
    "            \"body_mass_index\": example[\"bmi\"],\n",
    "        },\n",
    "        static_categorical_covariates={\n",
    "            \"gender\": example[\"sex\"],\n",
    "        },\n",
    "        freq=[0] * len(example[\"inputs\"]),\n",
    "        xreg_mode=\"xreg + timesfm\",              # default\n",
    "        ridge=0.0,\n",
    "        force_on_cpu=False,\n",
    "        normalize_xreg_target_per_input=True,    # default\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\rFinished batch {i} linear in {time.time() - start_time} seconds\",\n",
    "        end=\"\",\n",
    "    )\n",
    "    # print()\n",
    "    raw_forecast = raw_forecast[:, :horizon_len]\n",
    "    true_series = np.array(example[\"outputs\"])[:, :horizon_len]\n",
    "    ground_true_labels.extend(example[\"label\"])\n",
    "\n",
    "    metrics[\"eval_mae_timesfm\"].extend(mae(raw_forecast, true_series))\n",
    "    metrics[\"eval_mae_xreg_timesfm\"].extend(mae(cov_forecast, true_series))\n",
    "    metrics[\"eval_mae_xreg\"].extend(mae(ols_forecast, true_series))\n",
    "    metrics[\"eval_mse_timesfm\"].extend(mse(raw_forecast[:, :horizon_len], true_series))\n",
    "    metrics[\"eval_mse_xreg_timesfm\"].extend(mse(cov_forecast, true_series))\n",
    "    metrics[\"eval_mse_xreg\"].extend(mse(ols_forecast, true_series))\n",
    "    metrics[\"eval_pred_lable_timesfm\"].extend(user_definable_IOH(raw_forecast))\n",
    "    metrics[\"eval_pred_lable_xreg_timesfm\"].extend(user_definable_IOH(cov_forecast))\n",
    "    metrics[\"eval_pred_lable_xreg\"].extend(user_definable_IOH(ols_forecast))\n",
    "\n",
    "print()\n",
    "\n",
    "for k, v in metrics.items():\n",
    "  if k in [\"eval_pred_lable_timesfm\", \"eval_pred_lable_xreg_timesfm\", \"eval_pred_lable_xreg\"]:\n",
    "    print(k, \"--Prediction Results:\")\n",
    "    precision, recall, thmbps = precision_recall_curve(ground_true_labels, v)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "    fpr, tpr, thmbps = roc_curve(ground_true_labels, v)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    f1 = f1_score(ground_true_labels, v)\n",
    "    acc = accuracy_score(ground_true_labels, v)\n",
    "    tn, fp, fn, tp = confusion_matrix(ground_true_labels, v).ravel()\n",
    "\n",
    "    testres = 'auroc={:.3f}, auprc={:.3f} acc={:.3f}, F1={:.3f}, PPV={:.1f}, NPV={:.1f}, TN={}, fp={}, fn={}, TP={}'.format(auroc, auprc, acc, f1, tp/(tp+fp)*100, tn/(tn+fn)*100, tn, fp, fn, tp)\n",
    "    print(testres)\n",
    "  else:   \n",
    "    print(f\"{k}: {np.mean(v)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesfm_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
